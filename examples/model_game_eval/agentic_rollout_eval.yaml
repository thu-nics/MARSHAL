defaults:
  - ../config/envs@_here_
  - ../config/deepspeed_zero@_here_
  - ../config/deepspeed_zero2@_here_
  - ../config/deepspeed_zero3@_here_
  - ../config/deepspeed_zero3_cpuoffload@_here_

hydra:
  run:
    dir: .
  output_subdir: null

exp_name: "agentic_pipeline"
seed: 42
# logging_dir: ./runs/logs
# output_dir: ./runs
# render_save_dir: ./runs/render
system_envs:
  USE_MODELSCOPE: '1'

#track_with: wandb
#tracker_kwargs:
#  api_key:
#  project: roll-agentic
#  name: ${exp_name}_sokoban
#  notes: "agentic_pipeline"
#  tags:
#    - agentic
#    - roll
#    - baseline

track_with: tensorboard
tracker_kwargs:
  log_dir: ./runs/tensorboard

num_gpus_per_node: 8

max_steps: 1
save_steps: 10000
logging_steps: 1
eval_steps: 10
resume_from_checkpoint: false

rollout_batch_size: 15000
sequence_length: 32768

reward_clip: 20
advantage_clip: 10.0
ppo_epochs: 1
adv_estimator: "reinforce"
#pg_clip: 0.1
#dual_clip_loss: True
init_kl_coef: 0.0
whiten_advantages: true
entropy_loss_coef: 0

pretrain: /mnt/public/yuanhuining/models/Qwen3-4B/

actor_infer:
  model_args:
    flash_attn: fa2
    disable_gradient_checkpointing: true
    dtype: bf16
  generating_args:
    max_new_tokens: 4096 # single-turn response length
    top_p: 0.99
    top_k: 100
    num_beams: 1
    temperature: 0.6
    num_return_sequences: 1
  data_args:
    template: qwen3
  strategy_args:
    strategy_name: vllm
    strategy_config:
      gpu_memory_utilization: 0.8
      block_size: 16
      load_format: auto # should set 'auto' here, because default load_format is 'dummy'
  device_mapping: list(range(0,8))

enable_response_mask: True
action_sep: "||"
use_turn_scores: False # important to GAE when applying token-level rewards to token-level advantages. If False, will take the sum of scores as the reward for the last turn.
enable_think: True # False -> no think RL
max_actions_per_traj: 50

custom_envs:
  TicTacToe-first-100:
    env_type: tictactoe
    max_actions_per_traj: ${max_actions_per_traj}
    grid_vocab: false
    env_config:
      built_in_opponent: mcts
      render_mode: text

  TicTacToe-second-100:
    env_type: tictactoe
    max_actions_per_traj: ${max_actions_per_traj}
    grid_vocab: false
    env_config:
      built_in_opponent: mcts
      opponent_player: 0
      render_mode: text

  TicTacToe-first-1000:
    env_type: tictactoe
    max_actions_per_traj: ${max_actions_per_traj}
    grid_vocab: false
    env_config:
      built_in_opponent: mcts
      max_simulations: 1000
      render_mode: text

  TicTacToe-second-1000:
    env_type: tictactoe
    max_actions_per_traj: ${max_actions_per_traj}
    grid_vocab: false
    env_config:
      built_in_opponent: mcts
      opponent_player: 0
      max_simulations: 1000
      render_mode: text

  Connect4-first-10:
    env_type: connect_four
    max_actions_per_traj: ${max_actions_per_traj}
    grid_vocab: false
    env_config:
      built_in_opponent: mcts
      max_simulations: 10
      render_mode: text

  Connect4-second-10:
    env_type: connect_four
    max_actions_per_traj: ${max_actions_per_traj}
    grid_vocab: false
    env_config:
      built_in_opponent: mcts
      opponent_player: 0
      max_simulations: 10
      render_mode: text

  Connect4-first-100:
    env_type: connect_four
    max_actions_per_traj: ${max_actions_per_traj}
    grid_vocab: false
    env_config:
      built_in_opponent: mcts
      render_mode: text

  Connect4-second-100:
    env_type: connect_four
    max_actions_per_traj: ${max_actions_per_traj}
    grid_vocab: false
    env_config:
      built_in_opponent: mcts
      opponent_player: 0
      render_mode: text

  KuhnPoker-first:
    env_type: kuhn_poker
    max_actions_per_traj:  ${max_actions_per_traj}
    grid_vocab: false
    env_config:
      built_in_opponent: cfr
      render_mode: text

  KuhnPoker-second:
    env_type: kuhn_poker
    max_actions_per_traj:  ${max_actions_per_traj}
    grid_vocab: false
    env_config:
      built_in_opponent: cfr
      opponent_player: 0
      render_mode: text

  LeducPoker-first:
    env_type: leduc_poker
    max_actions_per_traj:  ${max_actions_per_traj}
    grid_vocab: false
    env_config:
      built_in_opponent: ne
      render_mode: text

  LeducPoker-second:
    env_type: leduc_poker
    max_actions_per_traj:  ${max_actions_per_traj}
    grid_vocab: false
    env_config:
      built_in_opponent: ne
      opponent_player: 0
      render_mode: text

  MiniHanabi:
    env_type: hanabi
    max_actions_per_traj:  ${max_actions_per_traj}
    grid_vocab: false
    env_config:
      render_mode: text

  SimpleHanabi:
    env_type: hanabi
    max_actions_per_traj:  ${max_actions_per_traj}
    grid_vocab: false
    env_config:
      render_mode: text
      colors: 3
      ranks: 2
      hand_size: 5
      max_information_tokens: 8
      max_life_tokens: 3
      
  FullHanabi:
    env_type: hanabi
    max_actions_per_traj:  ${max_actions_per_traj}
    grid_vocab: false
    env_config:
      render_mode: text
      colors: 3
      ranks: 3
      hand_size: 5
      max_information_tokens: 8
      max_life_tokens: 3

train_env_manager:
  format_penalty: 0.05
  max_env_num_per_worker: 32
  env_groups: 480
  group_size: 1
  tags: [
    TicTacToe-first-100, 
    TicTacToe-second-100, 
    TicTacToe-first-1000, 
    TicTacToe-second-1000,
    Connect4-first-10,
    Connect4-second-10,
    Connect4-first-100,
    Connect4-second-100,
    KuhnPoker-first,
    KuhnPoker-second,
    LeducPoker-first,
    LeducPoker-second,
    MiniHanabi,
    SimpleHanabi,
    FullHanabi
  ]
  n_groups: [32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32] #
